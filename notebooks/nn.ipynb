{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 10:53:08.385068: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-07 10:53:08.392868: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-07 10:53:08.474827: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-07 10:53:08.476173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 10:53:09.466329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import awswrangler as wr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wr.s3.read_parquet(\"s3://citroen-cost-prediction/proccesed-data\").drop_duplicates(\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDropperTransformer(TransformerMixin):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None):\n",
    "        return X.drop(columns=self.columns)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    N = 20\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            input_dim=3,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            N,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            1, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "        )\n",
    "    )\n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(\n",
    "    df: pd.DataFrame,\n",
    "    random_state: int = 42,\n",
    "    target: str = \"coste\",\n",
    "    test_size: float = 0.3,\n",
    "):\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    print(f\"Training data size: {X_train.shape}\\nTest data size: {X_test.shape}\")\n",
    "    print(\"Trainging \")\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropper = ColumnDropperTransformer(\n",
    "    columns=[\n",
    "        \"direccion_origen\",\n",
    "        \"direccion_destino\",\n",
    "        \"fecha\",\n",
    "        \"hora_salida\",\n",
    "        \"hora_llegada\",\n",
    "        \"consumo_medio\",\n",
    "    ]\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "model = KerasRegressor(model=create_model, epochs=300, batch_size=10)\n",
    "pipe = Pipeline(steps=[(\"dropper\", dropper), (\"scaler\", scaler), (\"model\", model)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (817, 9)\n",
      "Test data size: (205, 9)\n",
      "Trainging \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_split(df=df, target=\"coste\", test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "66/66 [==============================] - 1s 6ms/step - loss: 21.3636 - mse: 20.4252 - val_loss: 29.8683 - val_mse: 29.1785\n",
      "Epoch 2/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 20.9402 - mse: 20.4252 - val_loss: 29.5350 - val_mse: 29.1785\n",
      "Epoch 3/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 20.6737 - mse: 20.4252 - val_loss: 29.3331 - val_mse: 29.1785\n",
      "Epoch 4/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 20.4110 - mse: 20.3130 - val_loss: 28.7420 - val_mse: 28.6856\n",
      "Epoch 5/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 19.5641 - mse: 19.5188 - val_loss: 26.8381 - val_mse: 26.7901\n",
      "Epoch 6/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 16.9982 - mse: 16.9399 - val_loss: 22.4254 - val_mse: 22.3477\n",
      "Epoch 7/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 13.9421 - mse: 13.8495 - val_loss: 14.8339 - val_mse: 14.7241\n",
      "Epoch 8/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 5.4892 - mse: 5.3547 - val_loss: 1.1358 - val_mse: 0.9820\n",
      "Epoch 9/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.6358 - mse: 0.4778 - val_loss: 0.8709 - val_mse: 0.7083\n",
      "Epoch 10/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5314 - mse: 0.3734 - val_loss: 0.3810 - val_mse: 0.2243\n",
      "Epoch 11/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4463 - mse: 0.2913 - val_loss: 0.3502 - val_mse: 0.1961\n",
      "Epoch 12/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3676 - mse: 0.2121 - val_loss: 0.4004 - val_mse: 0.2440\n",
      "Epoch 13/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3622 - mse: 0.2076 - val_loss: 0.3243 - val_mse: 0.1695\n",
      "Epoch 14/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3444 - mse: 0.1904 - val_loss: 0.3900 - val_mse: 0.2351\n",
      "Epoch 15/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3678 - mse: 0.2143 - val_loss: 0.2973 - val_mse: 0.1434\n",
      "Epoch 16/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3209 - mse: 0.1674 - val_loss: 1.1681 - val_mse: 1.0106\n",
      "Epoch 17/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3499 - mse: 0.1957 - val_loss: 0.3370 - val_mse: 0.1822\n",
      "Epoch 18/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3323 - mse: 0.1790 - val_loss: 0.6591 - val_mse: 0.5031\n",
      "Epoch 19/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3001 - mse: 0.1465 - val_loss: 0.3783 - val_mse: 0.2274\n",
      "Epoch 20/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2974 - mse: 0.1446 - val_loss: 0.4411 - val_mse: 0.2861\n",
      "Epoch 21/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2956 - mse: 0.1425 - val_loss: 0.3011 - val_mse: 0.1476\n",
      "Epoch 22/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3115 - mse: 0.1586 - val_loss: 0.2607 - val_mse: 0.1081\n",
      "Epoch 23/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3069 - mse: 0.1545 - val_loss: 0.2832 - val_mse: 0.1306\n",
      "Epoch 24/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3142 - mse: 0.1620 - val_loss: 0.2528 - val_mse: 0.1016\n",
      "Epoch 25/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2879 - mse: 0.1356 - val_loss: 0.3081 - val_mse: 0.1578\n",
      "Epoch 26/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2784 - mse: 0.1271 - val_loss: 0.3114 - val_mse: 0.1593\n",
      "Epoch 27/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2621 - mse: 0.1110 - val_loss: 0.2645 - val_mse: 0.1134\n",
      "Epoch 28/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2831 - mse: 0.1318 - val_loss: 0.4972 - val_mse: 0.3444\n",
      "Epoch 29/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2757 - mse: 0.1247 - val_loss: 0.2980 - val_mse: 0.1476\n",
      "Epoch 30/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2644 - mse: 0.1139 - val_loss: 0.4120 - val_mse: 0.2650\n",
      "Epoch 31/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2862 - mse: 0.1360 - val_loss: 0.2627 - val_mse: 0.1123\n",
      "Epoch 32/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2853 - mse: 0.1351 - val_loss: 0.2645 - val_mse: 0.1142\n",
      "Epoch 33/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2748 - mse: 0.1247 - val_loss: 0.2454 - val_mse: 0.0964\n",
      "Epoch 34/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2984 - mse: 0.1478 - val_loss: 0.4299 - val_mse: 0.2779\n",
      "Epoch 35/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2873 - mse: 0.1371 - val_loss: 0.3002 - val_mse: 0.1490\n",
      "Epoch 36/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2781 - mse: 0.1275 - val_loss: 0.3776 - val_mse: 0.2258\n",
      "Epoch 37/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2921 - mse: 0.1417 - val_loss: 0.5517 - val_mse: 0.3989\n",
      "Epoch 38/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2895 - mse: 0.1398 - val_loss: 0.2670 - val_mse: 0.1171\n",
      "Epoch 39/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2710 - mse: 0.1216 - val_loss: 0.4359 - val_mse: 0.2860\n",
      "Epoch 40/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2698 - mse: 0.1202 - val_loss: 0.4929 - val_mse: 0.3417\n",
      "Epoch 41/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2750 - mse: 0.1260 - val_loss: 0.2368 - val_mse: 0.0888\n",
      "Epoch 42/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2837 - mse: 0.1350 - val_loss: 0.2452 - val_mse: 0.0968\n",
      "Epoch 43/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2755 - mse: 0.1270 - val_loss: 0.3471 - val_mse: 0.1973\n",
      "Epoch 44/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2682 - mse: 0.1196 - val_loss: 0.2443 - val_mse: 0.0970\n",
      "Epoch 45/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2899 - mse: 0.1414 - val_loss: 0.2618 - val_mse: 0.1140\n",
      "Epoch 46/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2563 - mse: 0.1081 - val_loss: 0.3068 - val_mse: 0.1579\n",
      "Epoch 47/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2580 - mse: 0.1099 - val_loss: 0.3154 - val_mse: 0.1662\n",
      "Epoch 48/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2615 - mse: 0.1132 - val_loss: 0.5601 - val_mse: 0.4167\n",
      "Epoch 49/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2905 - mse: 0.1432 - val_loss: 0.2871 - val_mse: 0.1390\n",
      "Epoch 50/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2732 - mse: 0.1258 - val_loss: 0.2387 - val_mse: 0.0920\n",
      "Epoch 51/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2705 - mse: 0.1236 - val_loss: 0.2419 - val_mse: 0.0961\n",
      "Epoch 52/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2636 - mse: 0.1168 - val_loss: 0.2652 - val_mse: 0.1183\n",
      "Epoch 53/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2752 - mse: 0.1287 - val_loss: 0.2792 - val_mse: 0.1322\n",
      "Epoch 54/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2657 - mse: 0.1191 - val_loss: 0.2871 - val_mse: 0.1429\n",
      "Epoch 55/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2884 - mse: 0.1422 - val_loss: 0.3127 - val_mse: 0.1660\n",
      "Epoch 56/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2664 - mse: 0.1198 - val_loss: 0.4993 - val_mse: 0.3506\n",
      "Epoch 57/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2603 - mse: 0.1144 - val_loss: 0.3098 - val_mse: 0.1662\n",
      "Epoch 58/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2605 - mse: 0.1152 - val_loss: 0.2480 - val_mse: 0.1029\n",
      "Epoch 59/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2623 - mse: 0.1171 - val_loss: 0.3629 - val_mse: 0.2170\n",
      "Epoch 60/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - mse: 0.1039 - val_loss: 0.3088 - val_mse: 0.1666\n",
      "Epoch 61/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2768 - mse: 0.1320 - val_loss: 0.3080 - val_mse: 0.1658\n",
      "Epoch 62/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2615 - mse: 0.1167 - val_loss: 0.2523 - val_mse: 0.1078\n",
      "Epoch 63/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - mse: 0.1028 - val_loss: 0.4330 - val_mse: 0.2863\n",
      "Epoch 64/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2625 - mse: 0.1178 - val_loss: 0.4051 - val_mse: 0.2590\n",
      "Epoch 65/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2793 - mse: 0.1346 - val_loss: 0.4658 - val_mse: 0.3201\n",
      "Epoch 66/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2888 - mse: 0.1447 - val_loss: 0.2521 - val_mse: 0.1089\n",
      "Epoch 67/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2447 - mse: 0.1012 - val_loss: 0.6007 - val_mse: 0.4540\n",
      "Epoch 68/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2776 - mse: 0.1340 - val_loss: 0.4439 - val_mse: 0.2978\n",
      "Epoch 69/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2719 - mse: 0.1273 - val_loss: 0.2344 - val_mse: 0.0918\n",
      "Epoch 70/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2597 - mse: 0.1158 - val_loss: 0.3344 - val_mse: 0.1902\n",
      "Epoch 71/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2425 - mse: 0.0988 - val_loss: 1.1683 - val_mse: 1.0203\n",
      "Epoch 72/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2699 - mse: 0.1261 - val_loss: 0.2990 - val_mse: 0.1545\n",
      "Epoch 73/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2698 - mse: 0.1264 - val_loss: 0.2662 - val_mse: 0.1251\n",
      "Epoch 74/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2716 - mse: 0.1285 - val_loss: 0.2847 - val_mse: 0.1410\n",
      "Epoch 75/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2519 - mse: 0.1091 - val_loss: 0.3670 - val_mse: 0.2229\n",
      "Epoch 76/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2676 - mse: 0.1247 - val_loss: 0.2674 - val_mse: 0.1262\n",
      "Epoch 77/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - mse: 0.1073 - val_loss: 0.2586 - val_mse: 0.1157\n",
      "Epoch 78/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2844 - mse: 0.1417 - val_loss: 0.3425 - val_mse: 0.1987\n",
      "Epoch 79/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2746 - mse: 0.1319 - val_loss: 0.2862 - val_mse: 0.1432\n",
      "Epoch 80/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2606 - mse: 0.1177 - val_loss: 0.3091 - val_mse: 0.1657\n",
      "Epoch 81/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2561 - mse: 0.1134 - val_loss: 0.3574 - val_mse: 0.2136\n",
      "Epoch 82/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2402 - mse: 0.0976 - val_loss: 0.2497 - val_mse: 0.1083\n",
      "Epoch 83/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2532 - mse: 0.1115 - val_loss: 0.2345 - val_mse: 0.0936\n",
      "Epoch 84/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2597 - mse: 0.1180 - val_loss: 0.2393 - val_mse: 0.0985\n",
      "Epoch 85/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2713 - mse: 0.1300 - val_loss: 0.8478 - val_mse: 0.7034\n",
      "Epoch 86/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2469 - mse: 0.1056 - val_loss: 0.2290 - val_mse: 0.0879\n",
      "Epoch 87/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2544 - mse: 0.1133 - val_loss: 0.2375 - val_mse: 0.0969\n",
      "Epoch 88/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2351 - mse: 0.0947 - val_loss: 0.2836 - val_mse: 0.1458\n",
      "Epoch 89/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2691 - mse: 0.1284 - val_loss: 0.2206 - val_mse: 0.0810\n",
      "Epoch 90/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2563 - mse: 0.1155 - val_loss: 0.3634 - val_mse: 0.2256\n",
      "Epoch 91/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2603 - mse: 0.1204 - val_loss: 0.2608 - val_mse: 0.1204\n",
      "Epoch 92/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2700 - mse: 0.1299 - val_loss: 0.4821 - val_mse: 0.3399\n",
      "Epoch 93/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2642 - mse: 0.1238 - val_loss: 0.5965 - val_mse: 0.4535\n",
      "Epoch 94/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2662 - mse: 0.1258 - val_loss: 0.2352 - val_mse: 0.0952\n",
      "Epoch 95/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2787 - mse: 0.1386 - val_loss: 0.2754 - val_mse: 0.1365\n",
      "Epoch 96/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2827 - mse: 0.1425 - val_loss: 0.8922 - val_mse: 0.7489\n",
      "Epoch 97/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2511 - mse: 0.1107 - val_loss: 0.2511 - val_mse: 0.1109\n",
      "Epoch 98/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - mse: 0.1106 - val_loss: 0.2657 - val_mse: 0.1254\n",
      "Epoch 99/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2656 - mse: 0.1255 - val_loss: 0.2446 - val_mse: 0.1048\n",
      "Epoch 100/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - mse: 0.1116 - val_loss: 0.2464 - val_mse: 0.1068\n",
      "Epoch 101/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2652 - mse: 0.1258 - val_loss: 0.2411 - val_mse: 0.1017\n",
      "Epoch 102/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2573 - mse: 0.1177 - val_loss: 0.2466 - val_mse: 0.1072\n",
      "Epoch 103/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2665 - mse: 0.1267 - val_loss: 0.2209 - val_mse: 0.0826\n",
      "Epoch 104/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2741 - mse: 0.1345 - val_loss: 0.2224 - val_mse: 0.0836\n",
      "Epoch 105/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2666 - mse: 0.1275 - val_loss: 0.2289 - val_mse: 0.0905\n",
      "Epoch 106/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2614 - mse: 0.1228 - val_loss: 0.3295 - val_mse: 0.1893\n",
      "Epoch 107/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2596 - mse: 0.1206 - val_loss: 0.2559 - val_mse: 0.1168\n",
      "Epoch 108/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2521 - mse: 0.1131 - val_loss: 0.2274 - val_mse: 0.0895\n",
      "Epoch 109/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2711 - mse: 0.1329 - val_loss: 0.2518 - val_mse: 0.1158\n",
      "Epoch 110/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2762 - mse: 0.1384 - val_loss: 0.3143 - val_mse: 0.1750\n",
      "Epoch 111/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2399 - mse: 0.1019 - val_loss: 0.2259 - val_mse: 0.0887\n",
      "Epoch 112/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2498 - mse: 0.1118 - val_loss: 0.2151 - val_mse: 0.0782\n",
      "Epoch 113/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2528 - mse: 0.1150 - val_loss: 0.2825 - val_mse: 0.1443\n",
      "Epoch 114/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2606 - mse: 0.1225 - val_loss: 0.2663 - val_mse: 0.1279\n",
      "Epoch 115/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - mse: 0.1135 - val_loss: 0.2501 - val_mse: 0.1120\n",
      "Epoch 116/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2738 - mse: 0.1359 - val_loss: 0.2702 - val_mse: 0.1318\n",
      "Epoch 117/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2355 - mse: 0.0974 - val_loss: 0.3140 - val_mse: 0.1748\n",
      "Epoch 118/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2793 - mse: 0.1412 - val_loss: 0.5578 - val_mse: 0.4171\n",
      "Epoch 119/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2402 - mse: 0.1022 - val_loss: 0.2996 - val_mse: 0.1645\n",
      "Epoch 120/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2403 - mse: 0.1029 - val_loss: 0.2102 - val_mse: 0.0738\n",
      "Epoch 121/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2766 - mse: 0.1391 - val_loss: 0.2266 - val_mse: 0.0908\n",
      "Epoch 122/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2659 - mse: 0.1283 - val_loss: 0.2605 - val_mse: 0.1228\n",
      "Epoch 123/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2466 - mse: 0.1090 - val_loss: 0.2102 - val_mse: 0.0740\n",
      "Epoch 124/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2765 - mse: 0.1396 - val_loss: 0.3012 - val_mse: 0.1633\n",
      "Epoch 125/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2721 - mse: 0.1354 - val_loss: 0.2124 - val_mse: 0.0763\n",
      "Epoch 126/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2612 - mse: 0.1241 - val_loss: 0.2831 - val_mse: 0.1453\n",
      "Epoch 127/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2629 - mse: 0.1259 - val_loss: 0.2258 - val_mse: 0.0887\n",
      "Epoch 128/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2413 - mse: 0.1040 - val_loss: 0.2390 - val_mse: 0.1017\n",
      "Epoch 129/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2681 - mse: 0.1307 - val_loss: 0.2579 - val_mse: 0.1230\n",
      "Epoch 130/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2524 - mse: 0.1156 - val_loss: 0.2591 - val_mse: 0.1239\n",
      "Epoch 131/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2648 - mse: 0.1270 - val_loss: 0.2436 - val_mse: 0.1077\n",
      "Epoch 132/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2566 - mse: 0.1195 - val_loss: 0.2200 - val_mse: 0.0833\n",
      "Epoch 133/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2578 - mse: 0.1205 - val_loss: 0.2686 - val_mse: 0.1312\n",
      "Epoch 134/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2741 - mse: 0.1377 - val_loss: 0.3961 - val_mse: 0.2579\n",
      "Epoch 135/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2496 - mse: 0.1134 - val_loss: 0.2248 - val_mse: 0.0899\n",
      "Epoch 136/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2626 - mse: 0.1257 - val_loss: 0.2593 - val_mse: 0.1228\n",
      "Epoch 137/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2366 - mse: 0.1001 - val_loss: 0.2458 - val_mse: 0.1091\n",
      "Epoch 138/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2645 - mse: 0.1280 - val_loss: 0.3700 - val_mse: 0.2325\n",
      "Epoch 139/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2625 - mse: 0.1262 - val_loss: 0.2829 - val_mse: 0.1457\n",
      "Epoch 140/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - mse: 0.1125 - val_loss: 0.4723 - val_mse: 0.3386\n",
      "Epoch 141/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2624 - mse: 0.1259 - val_loss: 0.7095 - val_mse: 0.5697\n",
      "Epoch 142/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2478 - mse: 0.1111 - val_loss: 0.2702 - val_mse: 0.1334\n",
      "Epoch 143/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2537 - mse: 0.1175 - val_loss: 0.9837 - val_mse: 0.8435\n",
      "Epoch 144/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2625 - mse: 0.1259 - val_loss: 0.2381 - val_mse: 0.1028\n",
      "Epoch 145/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2566 - mse: 0.1199 - val_loss: 0.2233 - val_mse: 0.0873\n",
      "Epoch 146/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2528 - mse: 0.1168 - val_loss: 0.3758 - val_mse: 0.2383\n",
      "Epoch 147/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - mse: 0.1151 - val_loss: 0.4632 - val_mse: 0.3251\n",
      "Epoch 148/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2688 - mse: 0.1327 - val_loss: 0.2917 - val_mse: 0.1546\n",
      "Epoch 149/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2791 - mse: 0.1425 - val_loss: 0.4674 - val_mse: 0.3299\n",
      "Epoch 150/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2402 - mse: 0.1043 - val_loss: 0.2924 - val_mse: 0.1560\n",
      "Epoch 151/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2522 - mse: 0.1158 - val_loss: 0.3975 - val_mse: 0.2597\n",
      "Epoch 152/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2568 - mse: 0.1206 - val_loss: 0.5219 - val_mse: 0.3834\n",
      "Epoch 153/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2637 - mse: 0.1276 - val_loss: 0.2110 - val_mse: 0.0761\n",
      "Epoch 154/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.1009 - val_loss: 0.3774 - val_mse: 0.2406\n",
      "Epoch 155/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - mse: 0.1137 - val_loss: 0.2194 - val_mse: 0.0855\n",
      "Epoch 156/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2289 - mse: 0.0935 - val_loss: 0.4654 - val_mse: 0.3281\n",
      "Epoch 157/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2423 - mse: 0.1070 - val_loss: 0.5015 - val_mse: 0.3642\n",
      "Epoch 158/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2274 - mse: 0.0925 - val_loss: 0.2150 - val_mse: 0.0808\n",
      "Epoch 159/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2735 - mse: 0.1380 - val_loss: 0.6649 - val_mse: 0.5271\n",
      "Epoch 160/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2515 - mse: 0.1167 - val_loss: 0.2598 - val_mse: 0.1270\n",
      "Epoch 161/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2298 - mse: 0.0953 - val_loss: 0.2877 - val_mse: 0.1522\n",
      "Epoch 162/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2459 - mse: 0.1109 - val_loss: 0.2463 - val_mse: 0.1130\n",
      "Epoch 163/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2455 - mse: 0.1105 - val_loss: 0.2681 - val_mse: 0.1358\n",
      "Epoch 164/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2481 - mse: 0.1130 - val_loss: 0.2631 - val_mse: 0.1281\n",
      "Epoch 165/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2634 - mse: 0.1290 - val_loss: 0.2179 - val_mse: 0.0842\n",
      "Epoch 166/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2512 - mse: 0.1172 - val_loss: 0.3008 - val_mse: 0.1655\n",
      "Epoch 167/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2395 - mse: 0.1052 - val_loss: 0.2693 - val_mse: 0.1343\n",
      "Epoch 168/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2213 - mse: 0.0870 - val_loss: 0.2168 - val_mse: 0.0841\n",
      "Epoch 169/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2527 - mse: 0.1184 - val_loss: 0.2173 - val_mse: 0.0840\n",
      "Epoch 170/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2561 - mse: 0.1217 - val_loss: 0.2871 - val_mse: 0.1520\n",
      "Epoch 171/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2281 - mse: 0.0937 - val_loss: 0.6365 - val_mse: 0.4996\n",
      "Epoch 172/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2550 - mse: 0.1207 - val_loss: 0.2369 - val_mse: 0.1037\n",
      "Epoch 173/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2273 - mse: 0.0928 - val_loss: 0.2176 - val_mse: 0.0835\n",
      "Epoch 174/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2572 - mse: 0.1230 - val_loss: 0.4431 - val_mse: 0.3071\n",
      "Epoch 175/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2572 - mse: 0.1232 - val_loss: 0.5080 - val_mse: 0.3720\n",
      "Epoch 176/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2274 - mse: 0.0936 - val_loss: 0.3300 - val_mse: 0.1950\n",
      "Epoch 177/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2551 - mse: 0.1211 - val_loss: 0.2846 - val_mse: 0.1537\n",
      "Epoch 178/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2455 - mse: 0.1120 - val_loss: 0.2214 - val_mse: 0.0882\n",
      "Epoch 179/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2652 - mse: 0.1318 - val_loss: 0.2288 - val_mse: 0.0953\n",
      "Epoch 180/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2547 - mse: 0.1211 - val_loss: 0.2584 - val_mse: 0.1244\n",
      "Epoch 181/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2523 - mse: 0.1187 - val_loss: 0.2332 - val_mse: 0.1015\n",
      "Epoch 182/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2367 - mse: 0.1033 - val_loss: 0.2441 - val_mse: 0.1104\n",
      "Epoch 183/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2387 - mse: 0.1054 - val_loss: 0.2357 - val_mse: 0.1023\n",
      "Epoch 184/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2536 - mse: 0.1201 - val_loss: 0.2254 - val_mse: 0.0921\n",
      "Epoch 185/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.1031 - val_loss: 0.3981 - val_mse: 0.2631\n",
      "Epoch 186/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2446 - mse: 0.1110 - val_loss: 0.2075 - val_mse: 0.0746\n",
      "Epoch 187/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2319 - mse: 0.0981 - val_loss: 0.2612 - val_mse: 0.1273\n",
      "Epoch 188/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2528 - mse: 0.1190 - val_loss: 0.2468 - val_mse: 0.1151\n",
      "Epoch 189/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2570 - mse: 0.1236 - val_loss: 0.2905 - val_mse: 0.1559\n",
      "Epoch 190/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2518 - mse: 0.1181 - val_loss: 0.2165 - val_mse: 0.0835\n",
      "Epoch 191/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2526 - mse: 0.1191 - val_loss: 0.6643 - val_mse: 0.5282\n",
      "Epoch 192/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2413 - mse: 0.1080 - val_loss: 0.2110 - val_mse: 0.0786\n",
      "Epoch 193/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2396 - mse: 0.1067 - val_loss: 0.2106 - val_mse: 0.0782\n",
      "Epoch 194/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2569 - mse: 0.1239 - val_loss: 0.2540 - val_mse: 0.1208\n",
      "Epoch 195/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2576 - mse: 0.1248 - val_loss: 0.2169 - val_mse: 0.0856\n",
      "Epoch 196/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2375 - mse: 0.1051 - val_loss: 0.3256 - val_mse: 0.1958\n",
      "Epoch 197/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2520 - mse: 0.1197 - val_loss: 0.2063 - val_mse: 0.0747\n",
      "Epoch 198/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2585 - mse: 0.1263 - val_loss: 0.3745 - val_mse: 0.2409\n",
      "Epoch 199/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2590 - mse: 0.1265 - val_loss: 0.2284 - val_mse: 0.0968\n",
      "Epoch 200/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2704 - mse: 0.1374 - val_loss: 0.4450 - val_mse: 0.3107\n",
      "Epoch 201/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2325 - mse: 0.0997 - val_loss: 0.3399 - val_mse: 0.2106\n",
      "Epoch 202/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2645 - mse: 0.1318 - val_loss: 0.2163 - val_mse: 0.0841\n",
      "Epoch 203/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2401 - mse: 0.1074 - val_loss: 0.2491 - val_mse: 0.1176\n",
      "Epoch 204/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2312 - mse: 0.0990 - val_loss: 0.4527 - val_mse: 0.3181\n",
      "Epoch 205/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2218 - mse: 0.0893 - val_loss: 0.2037 - val_mse: 0.0724\n",
      "Epoch 206/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2500 - mse: 0.1171 - val_loss: 0.9875 - val_mse: 0.8511\n",
      "Epoch 207/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - mse: 0.1172 - val_loss: 0.2222 - val_mse: 0.0901\n",
      "Epoch 208/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2437 - mse: 0.1116 - val_loss: 0.2401 - val_mse: 0.1075\n",
      "Epoch 209/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2636 - mse: 0.1316 - val_loss: 0.7340 - val_mse: 0.5990\n",
      "Epoch 210/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2456 - mse: 0.1128 - val_loss: 0.2171 - val_mse: 0.0855\n",
      "Epoch 211/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2577 - mse: 0.1253 - val_loss: 0.3324 - val_mse: 0.1988\n",
      "Epoch 212/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2668 - mse: 0.1344 - val_loss: 0.2609 - val_mse: 0.1283\n",
      "Epoch 213/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2418 - mse: 0.1095 - val_loss: 0.2076 - val_mse: 0.0763\n",
      "Epoch 214/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - mse: 0.1168 - val_loss: 0.4382 - val_mse: 0.3040\n",
      "Epoch 215/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2588 - mse: 0.1269 - val_loss: 0.2100 - val_mse: 0.0785\n",
      "Epoch 216/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2520 - mse: 0.1194 - val_loss: 0.3110 - val_mse: 0.1779\n",
      "Epoch 217/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2286 - mse: 0.0970 - val_loss: 0.6522 - val_mse: 0.5179\n",
      "Epoch 218/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2646 - mse: 0.1327 - val_loss: 0.4086 - val_mse: 0.2748\n",
      "Epoch 219/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2563 - mse: 0.1241 - val_loss: 0.4411 - val_mse: 0.3073\n",
      "Epoch 220/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2325 - mse: 0.1001 - val_loss: 0.2921 - val_mse: 0.1593\n",
      "Epoch 221/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2702 - mse: 0.1381 - val_loss: 0.2175 - val_mse: 0.0859\n",
      "Epoch 222/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2255 - mse: 0.0930 - val_loss: 0.3637 - val_mse: 0.2299\n",
      "Epoch 223/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2281 - mse: 0.0965 - val_loss: 0.4297 - val_mse: 0.2958\n",
      "Epoch 224/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2351 - mse: 0.1025 - val_loss: 0.4034 - val_mse: 0.2691\n",
      "Epoch 225/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2475 - mse: 0.1151 - val_loss: 0.3283 - val_mse: 0.1948\n",
      "Epoch 226/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2477 - mse: 0.1156 - val_loss: 0.2161 - val_mse: 0.0841\n",
      "Epoch 227/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2422 - mse: 0.1100 - val_loss: 0.3546 - val_mse: 0.2211\n",
      "Epoch 228/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2413 - mse: 0.1094 - val_loss: 0.2310 - val_mse: 0.0989\n",
      "Epoch 229/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2360 - mse: 0.1038 - val_loss: 0.2714 - val_mse: 0.1386\n",
      "Epoch 230/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2586 - mse: 0.1265 - val_loss: 0.2110 - val_mse: 0.0798\n",
      "Epoch 231/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2510 - mse: 0.1189 - val_loss: 0.2558 - val_mse: 0.1235\n",
      "Epoch 232/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2476 - mse: 0.1155 - val_loss: 0.2251 - val_mse: 0.0931\n",
      "Epoch 233/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2475 - mse: 0.1155 - val_loss: 0.2512 - val_mse: 0.1190\n",
      "Epoch 234/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2414 - mse: 0.1094 - val_loss: 0.3839 - val_mse: 0.2500\n",
      "Epoch 235/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2385 - mse: 0.1056 - val_loss: 0.2487 - val_mse: 0.1182\n",
      "Epoch 236/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2432 - mse: 0.1108 - val_loss: 0.5526 - val_mse: 0.4181\n",
      "Epoch 237/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2463 - mse: 0.1136 - val_loss: 0.4023 - val_mse: 0.2720\n",
      "Epoch 238/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2453 - mse: 0.1130 - val_loss: 0.2878 - val_mse: 0.1548\n",
      "Epoch 239/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.1045 - val_loss: 0.9224 - val_mse: 0.7871\n",
      "Epoch 240/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2622 - mse: 0.1300 - val_loss: 0.2568 - val_mse: 0.1241\n",
      "Epoch 241/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2258 - mse: 0.0938 - val_loss: 0.2224 - val_mse: 0.0908\n",
      "Epoch 242/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2447 - mse: 0.1123 - val_loss: 0.2215 - val_mse: 0.0905\n",
      "Epoch 243/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2377 - mse: 0.1053 - val_loss: 0.2648 - val_mse: 0.1351\n",
      "Epoch 244/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2343 - mse: 0.1027 - val_loss: 0.2090 - val_mse: 0.0780\n",
      "Epoch 245/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2670 - mse: 0.1351 - val_loss: 0.2351 - val_mse: 0.1034\n",
      "Epoch 246/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2435 - mse: 0.1112 - val_loss: 0.2870 - val_mse: 0.1570\n",
      "Epoch 247/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2430 - mse: 0.1110 - val_loss: 0.4603 - val_mse: 0.3264\n",
      "Epoch 248/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2322 - mse: 0.0996 - val_loss: 0.5062 - val_mse: 0.3776\n",
      "Epoch 249/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2515 - mse: 0.1201 - val_loss: 0.2419 - val_mse: 0.1105\n",
      "Epoch 250/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2479 - mse: 0.1161 - val_loss: 0.2555 - val_mse: 0.1229\n",
      "Epoch 251/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2283 - mse: 0.0962 - val_loss: 0.2739 - val_mse: 0.1411\n",
      "Epoch 252/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2285 - mse: 0.0963 - val_loss: 0.7857 - val_mse: 0.6501\n",
      "Epoch 253/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2558 - mse: 0.1240 - val_loss: 0.2147 - val_mse: 0.0840\n",
      "Epoch 254/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2451 - mse: 0.1132 - val_loss: 0.2654 - val_mse: 0.1356\n",
      "Epoch 255/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2528 - mse: 0.1209 - val_loss: 0.2203 - val_mse: 0.0894\n",
      "Epoch 256/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2526 - mse: 0.1209 - val_loss: 1.1899 - val_mse: 1.0539\n",
      "Epoch 257/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2433 - mse: 0.1108 - val_loss: 0.2321 - val_mse: 0.1017\n",
      "Epoch 258/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2571 - mse: 0.1252 - val_loss: 0.4016 - val_mse: 0.2686\n",
      "Epoch 259/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2354 - mse: 0.1035 - val_loss: 0.3734 - val_mse: 0.2441\n",
      "Epoch 260/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2353 - mse: 0.1039 - val_loss: 0.7125 - val_mse: 0.5777\n",
      "Epoch 261/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2473 - mse: 0.1157 - val_loss: 0.5227 - val_mse: 0.3945\n",
      "Epoch 262/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2451 - mse: 0.1138 - val_loss: 0.2417 - val_mse: 0.1100\n",
      "Epoch 263/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2279 - mse: 0.0965 - val_loss: 0.2337 - val_mse: 0.1040\n",
      "Epoch 264/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2462 - mse: 0.1144 - val_loss: 0.2115 - val_mse: 0.0809\n",
      "Epoch 265/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2323 - mse: 0.1009 - val_loss: 0.2799 - val_mse: 0.1477\n",
      "Epoch 266/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2384 - mse: 0.1067 - val_loss: 0.2313 - val_mse: 0.1018\n",
      "Epoch 267/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2409 - mse: 0.1101 - val_loss: 0.2344 - val_mse: 0.1051\n",
      "Epoch 268/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2524 - mse: 0.1213 - val_loss: 0.2668 - val_mse: 0.1353\n",
      "Epoch 269/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2359 - mse: 0.1048 - val_loss: 0.2500 - val_mse: 0.1207\n",
      "Epoch 270/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2341 - mse: 0.1034 - val_loss: 0.2318 - val_mse: 0.1009\n",
      "Epoch 271/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2389 - mse: 0.1085 - val_loss: 0.2236 - val_mse: 0.0944\n",
      "Epoch 272/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2324 - mse: 0.1017 - val_loss: 0.2181 - val_mse: 0.0887\n",
      "Epoch 273/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2344 - mse: 0.1036 - val_loss: 0.2822 - val_mse: 0.1508\n",
      "Epoch 274/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2506 - mse: 0.1200 - val_loss: 0.2087 - val_mse: 0.0786\n",
      "Epoch 275/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2632 - mse: 0.1327 - val_loss: 0.2180 - val_mse: 0.0876\n",
      "Epoch 276/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2374 - mse: 0.1068 - val_loss: 0.2362 - val_mse: 0.1061\n",
      "Epoch 277/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.1060 - val_loss: 0.3999 - val_mse: 0.2679\n",
      "Epoch 278/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2662 - mse: 0.1352 - val_loss: 0.2071 - val_mse: 0.0771\n",
      "Epoch 279/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2331 - mse: 0.1030 - val_loss: 0.2638 - val_mse: 0.1329\n",
      "Epoch 280/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2404 - mse: 0.1099 - val_loss: 0.2133 - val_mse: 0.0832\n",
      "Epoch 281/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2590 - mse: 0.1287 - val_loss: 0.2818 - val_mse: 0.1540\n",
      "Epoch 282/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2350 - mse: 0.1047 - val_loss: 0.2174 - val_mse: 0.0871\n",
      "Epoch 283/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2642 - mse: 0.1339 - val_loss: 0.5676 - val_mse: 0.4349\n",
      "Epoch 284/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2354 - mse: 0.1051 - val_loss: 0.3933 - val_mse: 0.2613\n",
      "Epoch 285/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2480 - mse: 0.1171 - val_loss: 0.3215 - val_mse: 0.1899\n",
      "Epoch 286/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2267 - mse: 0.0958 - val_loss: 0.3433 - val_mse: 0.2112\n",
      "Epoch 287/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2452 - mse: 0.1141 - val_loss: 0.3068 - val_mse: 0.1748\n",
      "Epoch 288/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2525 - mse: 0.1213 - val_loss: 0.2128 - val_mse: 0.0820\n",
      "Epoch 289/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2399 - mse: 0.1086 - val_loss: 0.2256 - val_mse: 0.0950\n",
      "Epoch 290/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2513 - mse: 0.1203 - val_loss: 0.2145 - val_mse: 0.0842\n",
      "Epoch 291/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2461 - mse: 0.1154 - val_loss: 0.2088 - val_mse: 0.0791\n",
      "Epoch 292/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2592 - mse: 0.1286 - val_loss: 0.2188 - val_mse: 0.0882\n",
      "Epoch 293/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2410 - mse: 0.1099 - val_loss: 0.4804 - val_mse: 0.3476\n",
      "Epoch 294/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2403 - mse: 0.1093 - val_loss: 0.2097 - val_mse: 0.0798\n",
      "Epoch 295/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2558 - mse: 0.1257 - val_loss: 0.4125 - val_mse: 0.2806\n",
      "Epoch 296/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2329 - mse: 0.1026 - val_loss: 0.2183 - val_mse: 0.0899\n",
      "Epoch 297/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2605 - mse: 0.1306 - val_loss: 0.1994 - val_mse: 0.0705\n",
      "Epoch 298/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2453 - mse: 0.1155 - val_loss: 0.3158 - val_mse: 0.1850\n",
      "Epoch 299/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2522 - mse: 0.1219 - val_loss: 0.2020 - val_mse: 0.0729\n",
      "Epoch 300/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - mse: 0.1185 - val_loss: 0.6877 - val_mse: 0.5548\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;dropper&#x27;,\n",
       "                 &lt;__main__.ColumnDropperTransformer object at 0x7f92c241a830&gt;),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 KerasRegressor(batch_size=10, epochs=300, model=&lt;function create_model at 0x7f92c3d3d090&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dropper&#x27;,\n",
       "                 &lt;__main__.ColumnDropperTransformer object at 0x7f92c241a830&gt;),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 KerasRegressor(batch_size=10, epochs=300, model=&lt;function create_model at 0x7f92c3d3d090&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnDropperTransformer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.ColumnDropperTransformer object at 0x7f92c241a830&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x7f92c3d3d090&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=300\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('dropper',\n",
       "                 <__main__.ColumnDropperTransformer object at 0x7f92c241a830>),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 KerasRegressor(batch_size=10, epochs=300, model=<function create_model at 0x7f92c3d3d090>))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    model__validation_split=0.2,\n",
    "    model__callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9722933664413795"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(model, X, y):\n",
    "    distancia = X.distancia.to_numpy()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(\"Performance\")\n",
    "    plt.xlabel(\"Distancia\")\n",
    "    plt.ylabel(\"Coste\")\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(distancia, y_pred, label=\"pred\", marker=\".\", alpha=0.3)\n",
    "    plt.scatter(distancia, y, label=\"true\", marker=\".\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plots(pipe, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(distancia: float, kilometraje: int, precio_carburante: float):\n",
    "    X = pd.DataFrame(\n",
    "        dict(\n",
    "            distancia=[distancia],\n",
    "            kilometraje=[kilometraje],\n",
    "            precio_carburante=[precio_carburante],\n",
    "        )\n",
    "    )\n",
    "    return float(np.squeeze(pipe[1:].predict(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1935589760541916"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_single(distancia=4.5, kilometraje=69700, precio_carburante=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n",
      "Maximum error reached in test set: 4.005829467773438. Real value: 20.86\n",
      "21/21 [==============================] - 0s 2ms/step\n",
      "Mean error in test set: -0.37867774242017327\n"
     ]
    }
   ],
   "source": [
    "def max_error(X_test, y_test):\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    diff = np.abs(y_test - pipe.predict(X_test))\n",
    "    argmax = np.argmax(diff)\n",
    "    max_err = diff[argmax]\n",
    "    y_max = y_test[argmax]\n",
    "    print(f\"Maximum error reached in test set: {max_err}. Real value: {y_max}\")\n",
    "\n",
    "\n",
    "def mean_error(X_test, y_test):\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    mean_err = np.mean(y_test - pipe.predict(X_test))\n",
    "    print(f\"Mean error in test set: {mean_err}\")\n",
    "\n",
    "\n",
    "max_error(X_test, y_test)\n",
    "mean_error(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
