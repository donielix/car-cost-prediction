{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 22:54:54.034774: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-03 22:54:54.037506: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-03 22:54:54.087994: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-03 22:54:54.089053: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 22:54:55.005585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import awswrangler as wr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wr.s3.read_parquet(\"s3://citroen-cost-prediction/proccesed-data\").drop_duplicates(\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDropperTransformer(TransformerMixin):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None):\n",
    "        return X.drop(columns=self.columns)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            16, input_dim=3, activation=\"relu\", kernel_regularizer=\"l2\"\n",
    "        )\n",
    "    )\n",
    "    model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"relu\"))\n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(\n",
    "    df: pd.DataFrame,\n",
    "    random_state: int = 42,\n",
    "    target: str = \"coste\",\n",
    "    test_size: float = 0.3,\n",
    "):\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    print(f\"Training data size: {X_train.shape}\\nTest data size: {X_test.shape}\")\n",
    "    print(\"Trainging \")\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropper = ColumnDropperTransformer(\n",
    "    columns=[\n",
    "        \"direccion_origen\",\n",
    "        \"direccion_destino\",\n",
    "        \"fecha\",\n",
    "        \"hora_salida\",\n",
    "        \"hora_llegada\",\n",
    "        \"consumo_medio\",\n",
    "    ]\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "model = KerasRegressor(model=create_model, epochs=300, batch_size=10)\n",
    "pipe = Pipeline(steps=[(\"dropper\", dropper), (\"scaler\", scaler), (\"model\", model)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (817, 9)\n",
      "Test data size: (205, 9)\n",
      "Trainging \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_split(df=df, target=\"coste\", test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "66/66 [==============================] - 1s 6ms/step - loss: 18.4732 - mse: 18.4189 - val_loss: 23.6516 - val_mse: 23.5979\n",
      "Epoch 2/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 13.4664 - mse: 13.4129 - val_loss: 15.1166 - val_mse: 15.0628\n",
      "Epoch 3/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.6155 - mse: 7.5616 - val_loss: 6.7687 - val_mse: 6.7145\n",
      "Epoch 4/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.1086 - mse: 2.0541 - val_loss: 1.0482 - val_mse: 0.9933\n",
      "Epoch 5/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.5488 - mse: 0.4940 - val_loss: 0.5468 - val_mse: 0.4922\n",
      "Epoch 6/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3950 - mse: 0.3408 - val_loss: 0.4507 - val_mse: 0.3968\n",
      "Epoch 7/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3318 - mse: 0.2782 - val_loss: 0.3828 - val_mse: 0.3294\n",
      "Epoch 8/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2853 - mse: 0.2324 - val_loss: 0.3283 - val_mse: 0.2759\n",
      "Epoch 9/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2732 - mse: 0.2212 - val_loss: 0.3479 - val_mse: 0.2965\n",
      "Epoch 10/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2262 - mse: 0.1751 - val_loss: 0.2706 - val_mse: 0.2198\n",
      "Epoch 11/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2011 - mse: 0.1507 - val_loss: 0.4908 - val_mse: 0.4407\n",
      "Epoch 12/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2147 - mse: 0.1650 - val_loss: 0.2367 - val_mse: 0.1873\n",
      "Epoch 13/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1840 - mse: 0.1350 - val_loss: 0.2312 - val_mse: 0.1827\n",
      "Epoch 14/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1653 - mse: 0.1172 - val_loss: 0.2752 - val_mse: 0.2275\n",
      "Epoch 15/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1900 - mse: 0.1427 - val_loss: 0.2333 - val_mse: 0.1862\n",
      "Epoch 16/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1595 - mse: 0.1127 - val_loss: 0.2250 - val_mse: 0.1785\n",
      "Epoch 17/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1533 - mse: 0.1073 - val_loss: 0.2768 - val_mse: 0.2313\n",
      "Epoch 18/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1657 - mse: 0.1204 - val_loss: 0.2785 - val_mse: 0.2337\n",
      "Epoch 19/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1585 - mse: 0.1140 - val_loss: 0.2627 - val_mse: 0.2184\n",
      "Epoch 20/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1567 - mse: 0.1129 - val_loss: 0.2152 - val_mse: 0.1718\n",
      "Epoch 21/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1627 - mse: 0.1195 - val_loss: 0.2125 - val_mse: 0.1696\n",
      "Epoch 22/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1588 - mse: 0.1162 - val_loss: 0.1837 - val_mse: 0.1414\n",
      "Epoch 23/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1628 - mse: 0.1207 - val_loss: 0.1764 - val_mse: 0.1347\n",
      "Epoch 24/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1438 - mse: 0.1024 - val_loss: 0.1999 - val_mse: 0.1587\n",
      "Epoch 25/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1485 - mse: 0.1076 - val_loss: 0.1800 - val_mse: 0.1393\n",
      "Epoch 26/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1514 - mse: 0.1110 - val_loss: 0.1887 - val_mse: 0.1486\n",
      "Epoch 27/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1388 - mse: 0.0989 - val_loss: 0.1870 - val_mse: 0.1472\n",
      "Epoch 28/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1514 - mse: 0.1118 - val_loss: 0.1802 - val_mse: 0.1408\n",
      "Epoch 29/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1551 - mse: 0.1158 - val_loss: 0.1926 - val_mse: 0.1536\n",
      "Epoch 30/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1304 - mse: 0.0915 - val_loss: 0.1722 - val_mse: 0.1336\n",
      "Epoch 31/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1343 - mse: 0.0958 - val_loss: 0.1985 - val_mse: 0.1601\n",
      "Epoch 32/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1399 - mse: 0.1019 - val_loss: 0.3318 - val_mse: 0.2940\n",
      "Epoch 33/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1378 - mse: 0.1001 - val_loss: 0.1872 - val_mse: 0.1497\n",
      "Epoch 34/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1432 - mse: 0.1058 - val_loss: 0.2067 - val_mse: 0.1693\n",
      "Epoch 35/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1315 - mse: 0.0943 - val_loss: 0.3585 - val_mse: 0.3214\n",
      "Epoch 36/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1439 - mse: 0.1071 - val_loss: 0.1859 - val_mse: 0.1491\n",
      "Epoch 37/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1337 - mse: 0.0972 - val_loss: 0.1450 - val_mse: 0.1086\n",
      "Epoch 38/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1228 - mse: 0.0865 - val_loss: 0.1396 - val_mse: 0.1036\n",
      "Epoch 39/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1241 - mse: 0.0883 - val_loss: 0.1339 - val_mse: 0.0983\n",
      "Epoch 40/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1249 - mse: 0.0894 - val_loss: 0.1546 - val_mse: 0.1191\n",
      "Epoch 41/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1342 - mse: 0.0989 - val_loss: 0.1423 - val_mse: 0.1070\n",
      "Epoch 42/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1192 - mse: 0.0841 - val_loss: 0.1699 - val_mse: 0.1349\n",
      "Epoch 43/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1238 - mse: 0.0889 - val_loss: 0.4659 - val_mse: 0.4309\n",
      "Epoch 44/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1237 - mse: 0.0889 - val_loss: 0.1406 - val_mse: 0.1061\n",
      "Epoch 45/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1280 - mse: 0.0935 - val_loss: 0.2878 - val_mse: 0.2534\n",
      "Epoch 46/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1260 - mse: 0.0917 - val_loss: 0.1622 - val_mse: 0.1280\n",
      "Epoch 47/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1185 - mse: 0.0845 - val_loss: 0.3823 - val_mse: 0.3484\n",
      "Epoch 48/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1202 - mse: 0.0864 - val_loss: 0.1601 - val_mse: 0.1266\n",
      "Epoch 49/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1282 - mse: 0.0947 - val_loss: 0.1436 - val_mse: 0.1101\n",
      "Epoch 50/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1225 - mse: 0.0891 - val_loss: 0.1460 - val_mse: 0.1127\n",
      "Epoch 51/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1304 - mse: 0.0973 - val_loss: 0.4112 - val_mse: 0.3779\n",
      "Epoch 52/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1239 - mse: 0.0909 - val_loss: 0.2101 - val_mse: 0.1771\n",
      "Epoch 53/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1269 - mse: 0.0941 - val_loss: 0.1406 - val_mse: 0.1079\n",
      "Epoch 54/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1202 - mse: 0.0876 - val_loss: 0.2514 - val_mse: 0.2188\n",
      "Epoch 55/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1195 - mse: 0.0870 - val_loss: 0.1413 - val_mse: 0.1089\n",
      "Epoch 56/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1165 - mse: 0.0841 - val_loss: 0.1611 - val_mse: 0.1290\n",
      "Epoch 57/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1144 - mse: 0.0824 - val_loss: 0.1478 - val_mse: 0.1159\n",
      "Epoch 58/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1112 - mse: 0.0793 - val_loss: 0.1437 - val_mse: 0.1119\n",
      "Epoch 59/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1111 - mse: 0.0794 - val_loss: 0.1940 - val_mse: 0.1623\n",
      "Epoch 60/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1116 - mse: 0.0801 - val_loss: 0.1499 - val_mse: 0.1187\n",
      "Epoch 61/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1123 - mse: 0.0811 - val_loss: 0.1301 - val_mse: 0.0992\n",
      "Epoch 62/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1067 - mse: 0.0759 - val_loss: 0.1230 - val_mse: 0.0922\n",
      "Epoch 63/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1198 - mse: 0.0892 - val_loss: 0.1211 - val_mse: 0.0905\n",
      "Epoch 64/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.0709 - val_loss: 0.1207 - val_mse: 0.0903\n",
      "Epoch 65/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1175 - mse: 0.0871 - val_loss: 0.1242 - val_mse: 0.0940\n",
      "Epoch 66/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0988 - mse: 0.0686 - val_loss: 0.2971 - val_mse: 0.2668\n",
      "Epoch 67/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1085 - mse: 0.0784 - val_loss: 0.1558 - val_mse: 0.1257\n",
      "Epoch 68/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1070 - mse: 0.0770 - val_loss: 0.1608 - val_mse: 0.1310\n",
      "Epoch 69/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1136 - mse: 0.0839 - val_loss: 0.1639 - val_mse: 0.1343\n",
      "Epoch 70/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1018 - mse: 0.0724 - val_loss: 0.1452 - val_mse: 0.1159\n",
      "Epoch 71/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1079 - mse: 0.0787 - val_loss: 0.2105 - val_mse: 0.1812\n",
      "Epoch 72/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1114 - mse: 0.0823 - val_loss: 0.1380 - val_mse: 0.1091\n",
      "Epoch 73/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1042 - mse: 0.0753 - val_loss: 0.1531 - val_mse: 0.1244\n",
      "Epoch 74/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1031 - mse: 0.0744 - val_loss: 0.1894 - val_mse: 0.1608\n",
      "Epoch 75/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1131 - mse: 0.0846 - val_loss: 0.1391 - val_mse: 0.1106\n",
      "Epoch 76/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1017 - mse: 0.0734 - val_loss: 0.2466 - val_mse: 0.2183\n",
      "Epoch 77/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1050 - mse: 0.0768 - val_loss: 0.1340 - val_mse: 0.1058\n",
      "Epoch 78/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.0751 - val_loss: 0.1625 - val_mse: 0.1345\n",
      "Epoch 79/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1072 - mse: 0.0793 - val_loss: 0.1738 - val_mse: 0.1460\n",
      "Epoch 80/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1049 - mse: 0.0772 - val_loss: 0.1749 - val_mse: 0.1472\n",
      "Epoch 81/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1056 - mse: 0.0780 - val_loss: 0.1664 - val_mse: 0.1389\n",
      "Epoch 82/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1098 - mse: 0.0824 - val_loss: 0.1712 - val_mse: 0.1438\n",
      "Epoch 83/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0990 - mse: 0.0719 - val_loss: 0.1292 - val_mse: 0.1021\n",
      "Epoch 84/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.0744 - val_loss: 0.1239 - val_mse: 0.0970\n",
      "Epoch 85/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1066 - mse: 0.0798 - val_loss: 0.1661 - val_mse: 0.1392\n",
      "Epoch 86/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1016 - mse: 0.0749 - val_loss: 0.1554 - val_mse: 0.1287\n",
      "Epoch 87/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1058 - mse: 0.0791 - val_loss: 0.2012 - val_mse: 0.1747\n",
      "Epoch 88/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1060 - mse: 0.0796 - val_loss: 0.1232 - val_mse: 0.0967\n",
      "Epoch 89/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0964 - mse: 0.0700 - val_loss: 0.1085 - val_mse: 0.0824\n",
      "Epoch 90/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0933 - mse: 0.0672 - val_loss: 0.1436 - val_mse: 0.1175\n",
      "Epoch 91/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1025 - mse: 0.0764 - val_loss: 0.1144 - val_mse: 0.0885\n",
      "Epoch 92/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1070 - mse: 0.0811 - val_loss: 0.1588 - val_mse: 0.1329\n",
      "Epoch 93/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0967 - mse: 0.0709 - val_loss: 0.1122 - val_mse: 0.0865\n",
      "Epoch 94/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1006 - mse: 0.0749 - val_loss: 0.1641 - val_mse: 0.1384\n",
      "Epoch 95/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1079 - mse: 0.0824 - val_loss: 0.1213 - val_mse: 0.0959\n",
      "Epoch 96/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1040 - mse: 0.0786 - val_loss: 0.1343 - val_mse: 0.1090\n",
      "Epoch 97/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0915 - mse: 0.0662 - val_loss: 0.1363 - val_mse: 0.1111\n",
      "Epoch 98/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1004 - mse: 0.0752 - val_loss: 0.2813 - val_mse: 0.2564\n",
      "Epoch 99/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1034 - mse: 0.0784 - val_loss: 0.1176 - val_mse: 0.0926\n",
      "Epoch 100/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0914 - mse: 0.0665 - val_loss: 0.1168 - val_mse: 0.0922\n",
      "Epoch 101/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0918 - mse: 0.0672 - val_loss: 0.1758 - val_mse: 0.1512\n",
      "Epoch 102/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0967 - mse: 0.0722 - val_loss: 0.1275 - val_mse: 0.1030\n",
      "Epoch 103/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1030 - mse: 0.0785 - val_loss: 0.1148 - val_mse: 0.0905\n",
      "Epoch 104/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0694 - val_loss: 0.1286 - val_mse: 0.1045\n",
      "Epoch 105/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1035 - mse: 0.0794 - val_loss: 0.1537 - val_mse: 0.1297\n",
      "Epoch 106/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0984 - mse: 0.0744 - val_loss: 0.1657 - val_mse: 0.1418\n",
      "Epoch 107/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0915 - mse: 0.0677 - val_loss: 0.2842 - val_mse: 0.2604\n",
      "Epoch 108/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0891 - mse: 0.0654 - val_loss: 0.1304 - val_mse: 0.1068\n",
      "Epoch 109/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0980 - mse: 0.0745 - val_loss: 0.1147 - val_mse: 0.0912\n",
      "Epoch 110/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0719 - val_loss: 0.1103 - val_mse: 0.0869\n",
      "Epoch 111/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0951 - mse: 0.0718 - val_loss: 0.1186 - val_mse: 0.0954\n",
      "Epoch 112/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0977 - mse: 0.0745 - val_loss: 0.1187 - val_mse: 0.0955\n",
      "Epoch 113/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0723 - val_loss: 0.1433 - val_mse: 0.1202\n",
      "Epoch 114/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0936 - mse: 0.0705 - val_loss: 0.1763 - val_mse: 0.1534\n",
      "Epoch 115/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1014 - mse: 0.0785 - val_loss: 0.1708 - val_mse: 0.1480\n",
      "Epoch 116/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0854 - mse: 0.0626 - val_loss: 0.1662 - val_mse: 0.1436\n",
      "Epoch 117/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0989 - mse: 0.0763 - val_loss: 0.1781 - val_mse: 0.1556\n",
      "Epoch 118/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0919 - mse: 0.0693 - val_loss: 0.1559 - val_mse: 0.1332\n",
      "Epoch 119/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1088 - mse: 0.0863 - val_loss: 0.1157 - val_mse: 0.0932\n",
      "Epoch 120/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0907 - mse: 0.0683 - val_loss: 0.1480 - val_mse: 0.1257\n",
      "Epoch 121/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1063 - mse: 0.0840 - val_loss: 0.1449 - val_mse: 0.1226\n",
      "Epoch 122/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0980 - mse: 0.0757 - val_loss: 0.1702 - val_mse: 0.1480\n",
      "Epoch 123/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0890 - mse: 0.0669 - val_loss: 0.1103 - val_mse: 0.0881\n",
      "Epoch 124/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0897 - mse: 0.0675 - val_loss: 0.1092 - val_mse: 0.0872\n",
      "Epoch 125/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0958 - mse: 0.0739 - val_loss: 0.1504 - val_mse: 0.1286\n",
      "Epoch 126/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0735 - val_loss: 0.1157 - val_mse: 0.0940\n",
      "Epoch 127/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0924 - mse: 0.0708 - val_loss: 0.2083 - val_mse: 0.1869\n",
      "Epoch 128/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1023 - mse: 0.0808 - val_loss: 0.1880 - val_mse: 0.1664\n",
      "Epoch 129/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0873 - mse: 0.0659 - val_loss: 0.1783 - val_mse: 0.1568\n",
      "Epoch 130/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0942 - mse: 0.0729 - val_loss: 0.1357 - val_mse: 0.1144\n",
      "Epoch 131/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0700 - val_loss: 0.1311 - val_mse: 0.1100\n",
      "Epoch 132/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0941 - mse: 0.0730 - val_loss: 0.1063 - val_mse: 0.0852\n",
      "Epoch 133/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0878 - mse: 0.0668 - val_loss: 0.1140 - val_mse: 0.0929\n",
      "Epoch 134/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0957 - mse: 0.0746 - val_loss: 0.1543 - val_mse: 0.1333\n",
      "Epoch 135/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0871 - mse: 0.0663 - val_loss: 0.2004 - val_mse: 0.1794\n",
      "Epoch 136/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0862 - mse: 0.0654 - val_loss: 0.1847 - val_mse: 0.1640\n",
      "Epoch 137/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0974 - mse: 0.0768 - val_loss: 0.1359 - val_mse: 0.1152\n",
      "Epoch 138/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0846 - mse: 0.0640 - val_loss: 0.3119 - val_mse: 0.2913\n",
      "Epoch 139/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0981 - mse: 0.0776 - val_loss: 0.1032 - val_mse: 0.0829\n",
      "Epoch 140/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0920 - mse: 0.0716 - val_loss: 0.1252 - val_mse: 0.1049\n",
      "Epoch 141/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0899 - mse: 0.0695 - val_loss: 0.1205 - val_mse: 0.1001\n",
      "Epoch 142/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0830 - mse: 0.0626 - val_loss: 0.1108 - val_mse: 0.0906\n",
      "Epoch 143/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0886 - mse: 0.0684 - val_loss: 0.2034 - val_mse: 0.1831\n",
      "Epoch 144/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0919 - mse: 0.0717 - val_loss: 0.1129 - val_mse: 0.0929\n",
      "Epoch 145/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1056 - mse: 0.0855 - val_loss: 0.1099 - val_mse: 0.0898\n",
      "Epoch 146/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0799 - mse: 0.0599 - val_loss: 0.1391 - val_mse: 0.1191\n",
      "Epoch 147/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0889 - mse: 0.0689 - val_loss: 0.1354 - val_mse: 0.1155\n",
      "Epoch 148/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0913 - mse: 0.0715 - val_loss: 0.1100 - val_mse: 0.0902\n",
      "Epoch 149/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0738 - val_loss: 0.3513 - val_mse: 0.3314\n",
      "Epoch 150/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0923 - mse: 0.0726 - val_loss: 0.3829 - val_mse: 0.3631\n",
      "Epoch 151/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0758 - val_loss: 0.1582 - val_mse: 0.1386\n",
      "Epoch 152/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0869 - mse: 0.0674 - val_loss: 0.1617 - val_mse: 0.1422\n",
      "Epoch 153/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0716 - val_loss: 0.1203 - val_mse: 0.1008\n",
      "Epoch 154/300\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0931 - mse: 0.0737 - val_loss: 0.1411 - val_mse: 0.1216\n",
      "Epoch 155/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0810 - mse: 0.0615 - val_loss: 0.2167 - val_mse: 0.1974\n",
      "Epoch 156/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0902 - mse: 0.0709 - val_loss: 0.1595 - val_mse: 0.1402\n",
      "Epoch 157/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0936 - mse: 0.0743 - val_loss: 0.1264 - val_mse: 0.1072\n",
      "Epoch 158/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0933 - mse: 0.0741 - val_loss: 0.1190 - val_mse: 0.0998\n",
      "Epoch 159/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0836 - mse: 0.0645 - val_loss: 0.1860 - val_mse: 0.1671\n",
      "Epoch 160/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0854 - mse: 0.0664 - val_loss: 0.1293 - val_mse: 0.1103\n",
      "Epoch 161/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0871 - mse: 0.0682 - val_loss: 0.1116 - val_mse: 0.0926\n",
      "Epoch 162/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0807 - mse: 0.0618 - val_loss: 0.1002 - val_mse: 0.0813\n",
      "Epoch 163/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0919 - mse: 0.0731 - val_loss: 0.1203 - val_mse: 0.1014\n",
      "Epoch 164/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0806 - mse: 0.0617 - val_loss: 0.1927 - val_mse: 0.1739\n",
      "Epoch 165/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0873 - mse: 0.0686 - val_loss: 0.1170 - val_mse: 0.0982\n",
      "Epoch 166/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0861 - mse: 0.0675 - val_loss: 0.1435 - val_mse: 0.1249\n",
      "Epoch 167/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0943 - mse: 0.0758 - val_loss: 0.1950 - val_mse: 0.1765\n",
      "Epoch 168/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0785 - val_loss: 0.1667 - val_mse: 0.1482\n",
      "Epoch 169/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0698 - val_loss: 0.0969 - val_mse: 0.0785\n",
      "Epoch 170/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0838 - mse: 0.0654 - val_loss: 0.1116 - val_mse: 0.0934\n",
      "Epoch 171/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0699 - val_loss: 0.1373 - val_mse: 0.1190\n",
      "Epoch 172/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0869 - mse: 0.0687 - val_loss: 0.1013 - val_mse: 0.0832\n",
      "Epoch 173/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0803 - mse: 0.0621 - val_loss: 0.4138 - val_mse: 0.3955\n",
      "Epoch 174/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0897 - mse: 0.0715 - val_loss: 0.2025 - val_mse: 0.1844\n",
      "Epoch 175/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0771 - mse: 0.0591 - val_loss: 0.0963 - val_mse: 0.0784\n",
      "Epoch 176/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0877 - mse: 0.0697 - val_loss: 0.1642 - val_mse: 0.1463\n",
      "Epoch 177/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0933 - mse: 0.0755 - val_loss: 0.1251 - val_mse: 0.1074\n",
      "Epoch 178/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0881 - mse: 0.0703 - val_loss: 0.1204 - val_mse: 0.1026\n",
      "Epoch 179/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0897 - mse: 0.0719 - val_loss: 0.1182 - val_mse: 0.1004\n",
      "Epoch 180/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0899 - mse: 0.0721 - val_loss: 0.1469 - val_mse: 0.1292\n",
      "Epoch 181/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0775 - mse: 0.0599 - val_loss: 0.2433 - val_mse: 0.2256\n",
      "Epoch 182/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0842 - mse: 0.0666 - val_loss: 0.1011 - val_mse: 0.0836\n",
      "Epoch 183/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0903 - mse: 0.0727 - val_loss: 0.1129 - val_mse: 0.0954\n",
      "Epoch 184/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0801 - mse: 0.0627 - val_loss: 0.1617 - val_mse: 0.1443\n",
      "Epoch 185/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0882 - mse: 0.0708 - val_loss: 0.1348 - val_mse: 0.1174\n",
      "Epoch 186/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0860 - mse: 0.0685 - val_loss: 0.2198 - val_mse: 0.2024\n",
      "Epoch 187/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0852 - mse: 0.0679 - val_loss: 0.1497 - val_mse: 0.1323\n",
      "Epoch 188/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0812 - mse: 0.0639 - val_loss: 0.1426 - val_mse: 0.1251\n",
      "Epoch 189/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0835 - mse: 0.0661 - val_loss: 0.2047 - val_mse: 0.1875\n",
      "Epoch 190/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0900 - mse: 0.0728 - val_loss: 0.1926 - val_mse: 0.1753\n",
      "Epoch 191/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0740 - val_loss: 0.1082 - val_mse: 0.0910\n",
      "Epoch 192/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0821 - mse: 0.0649 - val_loss: 0.1087 - val_mse: 0.0916\n",
      "Epoch 193/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0797 - mse: 0.0626 - val_loss: 0.2074 - val_mse: 0.1902\n",
      "Epoch 194/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0822 - mse: 0.0652 - val_loss: 0.2130 - val_mse: 0.1959\n",
      "Epoch 195/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0933 - mse: 0.0762 - val_loss: 0.0996 - val_mse: 0.0826\n",
      "Epoch 196/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0854 - mse: 0.0683 - val_loss: 0.1304 - val_mse: 0.1134\n",
      "Epoch 197/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0839 - mse: 0.0669 - val_loss: 0.1194 - val_mse: 0.1025\n",
      "Epoch 198/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0786 - mse: 0.0617 - val_loss: 0.1174 - val_mse: 0.1004\n",
      "Epoch 199/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0843 - mse: 0.0674 - val_loss: 0.1308 - val_mse: 0.1140\n",
      "Epoch 200/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0564 - val_loss: 0.0974 - val_mse: 0.0807\n",
      "Epoch 201/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0884 - mse: 0.0715 - val_loss: 0.0997 - val_mse: 0.0829\n",
      "Epoch 202/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0843 - mse: 0.0674 - val_loss: 0.1304 - val_mse: 0.1136\n",
      "Epoch 203/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0919 - mse: 0.0751 - val_loss: 0.1030 - val_mse: 0.0863\n",
      "Epoch 204/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0857 - mse: 0.0690 - val_loss: 0.1055 - val_mse: 0.0889\n",
      "Epoch 205/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0871 - mse: 0.0705 - val_loss: 0.1735 - val_mse: 0.1570\n",
      "Epoch 206/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0801 - mse: 0.0636 - val_loss: 0.1558 - val_mse: 0.1392\n",
      "Epoch 207/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0787 - val_loss: 0.1677 - val_mse: 0.1511\n",
      "Epoch 208/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0757 - mse: 0.0592 - val_loss: 0.1167 - val_mse: 0.1002\n",
      "Epoch 209/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0874 - mse: 0.0709 - val_loss: 0.1023 - val_mse: 0.0859\n",
      "Epoch 210/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0866 - mse: 0.0702 - val_loss: 0.2727 - val_mse: 0.2562\n",
      "Epoch 211/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0849 - mse: 0.0685 - val_loss: 0.1087 - val_mse: 0.0923\n",
      "Epoch 212/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0822 - mse: 0.0658 - val_loss: 0.1216 - val_mse: 0.1053\n",
      "Epoch 213/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0879 - mse: 0.0716 - val_loss: 0.1092 - val_mse: 0.0929\n",
      "Epoch 214/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0843 - mse: 0.0679 - val_loss: 0.1019 - val_mse: 0.0857\n",
      "Epoch 215/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0785 - mse: 0.0623 - val_loss: 0.1006 - val_mse: 0.0845\n",
      "Epoch 216/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0851 - mse: 0.0690 - val_loss: 0.1662 - val_mse: 0.1500\n",
      "Epoch 217/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0830 - mse: 0.0669 - val_loss: 0.1804 - val_mse: 0.1642\n",
      "Epoch 218/300\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0806 - mse: 0.0645 - val_loss: 0.2161 - val_mse: 0.2000\n",
      "Epoch 219/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0788 - mse: 0.0628 - val_loss: 0.2947 - val_mse: 0.2786\n",
      "Epoch 220/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0749 - mse: 0.0589 - val_loss: 0.1104 - val_mse: 0.0946\n",
      "Epoch 221/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0889 - mse: 0.0730 - val_loss: 0.1289 - val_mse: 0.1129\n",
      "Epoch 222/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0884 - mse: 0.0724 - val_loss: 0.1519 - val_mse: 0.1359\n",
      "Epoch 223/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0824 - mse: 0.0665 - val_loss: 0.1075 - val_mse: 0.0917\n",
      "Epoch 224/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0899 - mse: 0.0740 - val_loss: 0.1119 - val_mse: 0.0961\n",
      "Epoch 225/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0811 - mse: 0.0652 - val_loss: 0.0983 - val_mse: 0.0824\n",
      "Epoch 226/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0854 - mse: 0.0695 - val_loss: 0.2334 - val_mse: 0.2175\n",
      "Epoch 227/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0813 - mse: 0.0654 - val_loss: 0.0986 - val_mse: 0.0829\n",
      "Epoch 228/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0815 - mse: 0.0657 - val_loss: 0.1080 - val_mse: 0.0922\n",
      "Epoch 229/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0801 - mse: 0.0644 - val_loss: 0.1720 - val_mse: 0.1563\n",
      "Epoch 230/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0773 - mse: 0.0617 - val_loss: 0.1192 - val_mse: 0.1037\n",
      "Epoch 231/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0780 - mse: 0.0625 - val_loss: 0.1415 - val_mse: 0.1260\n",
      "Epoch 232/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0830 - mse: 0.0674 - val_loss: 0.3433 - val_mse: 0.3278\n",
      "Epoch 233/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0810 - mse: 0.0655 - val_loss: 0.1057 - val_mse: 0.0902\n",
      "Epoch 234/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0781 - mse: 0.0626 - val_loss: 0.1011 - val_mse: 0.0857\n",
      "Epoch 235/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0855 - mse: 0.0701 - val_loss: 0.1326 - val_mse: 0.1172\n",
      "Epoch 236/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0872 - mse: 0.0717 - val_loss: 0.1820 - val_mse: 0.1665\n",
      "Epoch 237/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0866 - mse: 0.0712 - val_loss: 0.1132 - val_mse: 0.0979\n",
      "Epoch 238/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0834 - mse: 0.0680 - val_loss: 0.1174 - val_mse: 0.1021\n",
      "Epoch 239/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0750 - mse: 0.0598 - val_loss: 0.1698 - val_mse: 0.1546\n",
      "Epoch 240/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0816 - mse: 0.0663 - val_loss: 0.1129 - val_mse: 0.0976\n",
      "Epoch 241/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0810 - mse: 0.0657 - val_loss: 0.1459 - val_mse: 0.1307\n",
      "Epoch 242/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0751 - mse: 0.0599 - val_loss: 0.1401 - val_mse: 0.1250\n",
      "Epoch 243/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0775 - mse: 0.0624 - val_loss: 0.0992 - val_mse: 0.0842\n",
      "Epoch 244/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0828 - mse: 0.0677 - val_loss: 0.2653 - val_mse: 0.2501\n",
      "Epoch 245/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0844 - mse: 0.0693 - val_loss: 0.2011 - val_mse: 0.1861\n",
      "Epoch 246/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0753 - mse: 0.0603 - val_loss: 0.1573 - val_mse: 0.1423\n",
      "Epoch 247/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0903 - mse: 0.0753 - val_loss: 0.1099 - val_mse: 0.0950\n",
      "Epoch 248/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0742 - mse: 0.0593 - val_loss: 0.1342 - val_mse: 0.1193\n",
      "Epoch 249/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0927 - mse: 0.0778 - val_loss: 0.1128 - val_mse: 0.0980\n",
      "Epoch 250/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0562 - val_loss: 0.1913 - val_mse: 0.1765\n",
      "Epoch 251/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0678 - val_loss: 0.0957 - val_mse: 0.0811\n",
      "Epoch 252/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0865 - mse: 0.0718 - val_loss: 0.1296 - val_mse: 0.1150\n",
      "Epoch 253/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0758 - mse: 0.0612 - val_loss: 0.1252 - val_mse: 0.1106\n",
      "Epoch 254/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0877 - mse: 0.0732 - val_loss: 0.1538 - val_mse: 0.1392\n",
      "Epoch 255/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0879 - mse: 0.0733 - val_loss: 0.1216 - val_mse: 0.1069\n",
      "Epoch 256/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0762 - mse: 0.0616 - val_loss: 0.1412 - val_mse: 0.1266\n",
      "Epoch 257/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0829 - mse: 0.0683 - val_loss: 0.1343 - val_mse: 0.1197\n",
      "Epoch 258/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0869 - mse: 0.0723 - val_loss: 0.1049 - val_mse: 0.0903\n",
      "Epoch 259/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0795 - mse: 0.0649 - val_loss: 0.1033 - val_mse: 0.0887\n",
      "Epoch 260/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0796 - mse: 0.0651 - val_loss: 0.0877 - val_mse: 0.0733\n",
      "Epoch 261/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0650 - val_loss: 0.1046 - val_mse: 0.0903\n",
      "Epoch 262/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0832 - mse: 0.0688 - val_loss: 0.1070 - val_mse: 0.0927\n",
      "Epoch 263/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0650 - val_loss: 0.1028 - val_mse: 0.0885\n",
      "Epoch 264/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0754 - mse: 0.0610 - val_loss: 0.1481 - val_mse: 0.1337\n",
      "Epoch 265/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0823 - mse: 0.0680 - val_loss: 0.1119 - val_mse: 0.0976\n",
      "Epoch 266/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0745 - mse: 0.0603 - val_loss: 0.1146 - val_mse: 0.1004\n",
      "Epoch 267/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0859 - mse: 0.0716 - val_loss: 0.1107 - val_mse: 0.0965\n",
      "Epoch 268/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0858 - mse: 0.0715 - val_loss: 0.1461 - val_mse: 0.1318\n",
      "Epoch 269/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0582 - val_loss: 0.1538 - val_mse: 0.1396\n",
      "Epoch 270/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0792 - mse: 0.0650 - val_loss: 0.0950 - val_mse: 0.0808\n",
      "Epoch 271/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0623 - val_loss: 0.1426 - val_mse: 0.1284\n",
      "Epoch 272/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0809 - mse: 0.0668 - val_loss: 0.1548 - val_mse: 0.1407\n",
      "Epoch 273/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0816 - mse: 0.0676 - val_loss: 0.1818 - val_mse: 0.1678\n",
      "Epoch 274/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0747 - mse: 0.0606 - val_loss: 0.1235 - val_mse: 0.1095\n",
      "Epoch 275/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0552 - val_loss: 0.1091 - val_mse: 0.0951\n",
      "Epoch 276/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0839 - mse: 0.0700 - val_loss: 0.2357 - val_mse: 0.2217\n",
      "Epoch 277/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0868 - mse: 0.0728 - val_loss: 0.2131 - val_mse: 0.1991\n",
      "Epoch 278/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0803 - mse: 0.0664 - val_loss: 0.1088 - val_mse: 0.0949\n",
      "Epoch 279/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0789 - mse: 0.0649 - val_loss: 0.1480 - val_mse: 0.1340\n",
      "Epoch 280/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0568 - val_loss: 0.1076 - val_mse: 0.0937\n",
      "Epoch 281/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0708 - mse: 0.0570 - val_loss: 0.1050 - val_mse: 0.0913\n",
      "Epoch 282/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0865 - mse: 0.0727 - val_loss: 0.2687 - val_mse: 0.2548\n",
      "Epoch 283/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0714 - mse: 0.0577 - val_loss: 0.1825 - val_mse: 0.1689\n",
      "Epoch 284/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0774 - mse: 0.0637 - val_loss: 0.1267 - val_mse: 0.1131\n",
      "Epoch 285/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0756 - mse: 0.0620 - val_loss: 0.4473 - val_mse: 0.4336\n",
      "Epoch 286/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0882 - mse: 0.0747 - val_loss: 0.1348 - val_mse: 0.1212\n",
      "Epoch 287/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0568 - val_loss: 0.1910 - val_mse: 0.1775\n",
      "Epoch 288/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0737 - mse: 0.0601 - val_loss: 0.1063 - val_mse: 0.0928\n",
      "Epoch 289/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0659 - val_loss: 0.1022 - val_mse: 0.0887\n",
      "Epoch 290/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0789 - mse: 0.0655 - val_loss: 0.1319 - val_mse: 0.1185\n",
      "Epoch 291/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0575 - val_loss: 0.1116 - val_mse: 0.0982\n",
      "Epoch 292/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0793 - mse: 0.0660 - val_loss: 0.2074 - val_mse: 0.1941\n",
      "Epoch 293/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0588 - val_loss: 0.0877 - val_mse: 0.0744\n",
      "Epoch 294/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0744 - mse: 0.0612 - val_loss: 0.1400 - val_mse: 0.1267\n",
      "Epoch 295/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0751 - mse: 0.0618 - val_loss: 0.1181 - val_mse: 0.1048\n",
      "Epoch 296/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0585 - val_loss: 0.1044 - val_mse: 0.0912\n",
      "Epoch 297/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0594 - val_loss: 0.2166 - val_mse: 0.2034\n",
      "Epoch 298/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0760 - mse: 0.0627 - val_loss: 0.2041 - val_mse: 0.1908\n",
      "Epoch 299/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0771 - mse: 0.0638 - val_loss: 0.0846 - val_mse: 0.0714\n",
      "Epoch 300/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0835 - mse: 0.0703 - val_loss: 0.1420 - val_mse: 0.1287\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;dropper&#x27;,\n",
       "                 &lt;__main__.ColumnDropperTransformer object at 0x7f4e012d0910&gt;),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 KerasRegressor(batch_size=10, epochs=300, model=&lt;function create_model at 0x7f4d61059bd0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dropper&#x27;,\n",
       "                 &lt;__main__.ColumnDropperTransformer object at 0x7f4e012d0910&gt;),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 KerasRegressor(batch_size=10, epochs=300, model=&lt;function create_model at 0x7f4d61059bd0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnDropperTransformer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.ColumnDropperTransformer object at 0x7f4e012d0910&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x7f4d61059bd0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=300\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('dropper',\n",
       "                 <__main__.ColumnDropperTransformer object at 0x7f4e012d0910>),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 KerasRegressor(batch_size=10, epochs=300, model=<function create_model at 0x7f4d61059bd0>))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    model__validation_split=0.2,\n",
    "    model__callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9919088091060823"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(model, X, y):\n",
    "    distancia = X.distancia.to_numpy()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(\"Performance\")\n",
    "    plt.xlabel(\"Distancia\")\n",
    "    plt.ylabel(\"Coste\")\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(distancia, y_pred, label=\"pred\", marker=\".\", alpha=0.3)\n",
    "    plt.scatter(distancia, y, label=\"true\", marker=\".\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plots(pipe, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(distancia: float, kilometraje: int, precio_carburante: float):\n",
    "    X = pd.DataFrame(\n",
    "        dict(\n",
    "            distancia=[distancia],\n",
    "            kilometraje=[kilometraje],\n",
    "            precio_carburante=[precio_carburante],\n",
    "        )\n",
    "    )\n",
    "    return float(np.squeeze(pipe[1:].predict(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.292473554611206"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_single(distancia=18.2, kilometraje=69700, precio_carburante=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step\n",
      "Maximum error reached in test set: 2.674420013427735. Real value: 20.86\n",
      "21/21 [==============================] - 0s 1ms/step\n",
      "Mean error in test set: -0.10052365429953829\n"
     ]
    }
   ],
   "source": [
    "def max_error(X_test, y_test):\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    diff = np.abs(y_test - pipe.predict(X_test))\n",
    "    argmax = np.argmax(diff)\n",
    "    max_err = diff[argmax]\n",
    "    y_max = y_test[argmax]\n",
    "    print(f\"Maximum error reached in test set: {max_err}. Real value: {y_max}\")\n",
    "\n",
    "\n",
    "def mean_error(X_test, y_test):\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    mean_err = np.mean(y_test - pipe.predict(X_test))\n",
    "    print(f\"Mean error in test set: {mean_err}\")\n",
    "\n",
    "\n",
    "max_error(X_test, y_test)\n",
    "mean_error(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
